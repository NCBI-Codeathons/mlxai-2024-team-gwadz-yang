{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "624cec84-bec6-4253-98d2-5a052617a678",
   "metadata": {},
   "source": [
    "# Grouping Curated Names (CurName) using fuzzy string matching\n",
    "\n",
    "This is code that attempts to reduce the complexity of the \"CurName\" (curated name) in the curated SPARCLE dataset by grouping the values based on similarity using the Levenshtein distance as implemented in the `fuzzywuzzy` package's function `fuzz.ratio()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7048237e-89b0-41a0-9a93-461c8a98fd6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: fuzzywuzzy in /Users/christopher/Library/Python/3.9/lib/python/site-packages (0.18.0)\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: python-Levenshtein in /Users/christopher/Library/Python/3.9/lib/python/site-packages (0.25.0)\n",
      "Requirement already satisfied: Levenshtein==0.25.0 in /Users/christopher/Library/Python/3.9/lib/python/site-packages (from python-Levenshtein) (0.25.0)\n",
      "Requirement already satisfied: rapidfuzz<4.0.0,>=3.1.0 in /Users/christopher/Library/Python/3.9/lib/python/site-packages (from Levenshtein==0.25.0->python-Levenshtein) (3.6.1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# !{sys.executable} -m pip install scikit-learn\n",
    "!{sys.executable} -m pip install fuzzywuzzy\n",
    "!{sys.executable} -m pip install python-Levenshtein\n",
    "\n",
    "\n",
    "# import sklearn\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import silhouette_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7d6163-1885-4dd1-98fd-05d13840240b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os, json\n",
    "import fuzzywuzzy\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e527e73d-d03f-4e79-844b-3c06f032e7d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e110f456-d79e-42d1-b9e2-9ed3a03efdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read in the SPARCLE data CSV\n",
    "sfile = \"../data/SPARCLE_IDS_curated.csv\" # location of the SPARCLE curated dataset\n",
    "df = pd.read_csv(sfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a41d827-a8b5-48b8-ad3b-19e8abab88ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing and Exploration: we will do various pre-processing of the curated names (\"CurName\" column) text strings\n",
    "df['pCurName'] = df['CurName'].apply(lambda x: x.lower()) ## lowercase the text; is this necessary?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dca4fc3-fc6f-41c0-a860-28cbdfcc3cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Report on numbers of unique curated vs. preprocessed names\n",
    "cn = list(set(df.CurName)) # 14947 unique curated names\n",
    "pcn = list(set(df.pCurName)) # 14916 unique curated names after lower-casing\n",
    "\n",
    "print(\"{} unique curated names (CurName); \\n{} unique pre-processed curated names (pCurName)\".format(len(cn),len(pcn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43315751-ec53-4837-8e1f-20c13f542e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def group_strings(strings, threshold=90, write_groups=True):\n",
    "    \"\"\"\n",
    "    This approach groups similar strings together using the fuzz.ratio() function. \n",
    "    You can adjust the similarity threshold to adjust stringency of grouping.\n",
    "\n",
    "    Arguments:\n",
    "        strings (list or pandas series): the list of strings for which to find groupings\n",
    "        threshold (int): the similarity threshold used for grouping strings. Valid values are in range(0,100). Treshold of 100 will result in each unique string getting a unique group.\n",
    "    Returns dictionaries for storing groups of similar strings: \n",
    "        string_groups (dict): contains the group assignments for each string in strings\n",
    "        groups (dict): contains the groupings of strings for a given threshold\n",
    "    Example:\n",
    "        threshold=90\n",
    "        curated_names = df['pCurName']\n",
    "        string_groups, groups = group_strings(curated_names,threshold=threshold,write_groups=False)\n",
    "    \"\"\"\n",
    "\n",
    "    # if \"CurName_groups_{}_threshold.json\".format(threshold) file already exists, don't do this loop, instead read in groups:\n",
    "    groups_filename = \"../data/CurName_fuzzy_groups/CurName_groups_{}_threshold.json\".format(threshold)\n",
    "    groups_file = Path(groups_filename)\n",
    "    if groups_file.is_file():\n",
    "        print(\"Groups file already exists: {}\".format(groups_file))\n",
    "        with open(groups_file) as json_file:\n",
    "            groups = json.load(json_file)\n",
    "    else:\n",
    "        print(\"Grouping {} strings using fuzz.ratio() with threshold of {}\".format(len(strings),threshold))\n",
    "        groups = {}\n",
    "        for i in range(0,len(strings)):\n",
    "            string = strings[i]\n",
    "            i+=1\n",
    "            \n",
    "            msg = \"{}/{}: {}\".format(i,len(strings),string)\n",
    "            sys.stdout.write(\"\\r\" + str(msg).ljust(200, \" \"))\n",
    "            #print(\"{}/{}: {}\".format(i,len(strings),string))\n",
    "            \n",
    "            # Search for similar strings in existing groups\n",
    "            matched_group = None\n",
    "            for group in groups.values():\n",
    "                for existing_string in group:\n",
    "                    if fuzz.ratio(string, existing_string) > threshold:  # Adjust threshold as needed\n",
    "                        matched_group = group\n",
    "                        break\n",
    "                if matched_group:\n",
    "                    break\n",
    "            \n",
    "            # If a similar group is found, add string to that group\n",
    "            if matched_group:\n",
    "                matched_group.append(string)\n",
    "            else:\n",
    "                # Otherwise, create a new group\n",
    "                groups[string] = [string]\n",
    "\n",
    "        # export groups\n",
    "        if write_groups:\n",
    "            with open(groups_filename, 'w') as json_file:\n",
    "                json.dump(groups, json_file)\n",
    "\n",
    "    ## Normalize names\n",
    "    # add some code for picking the curated name from each group?\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "\n",
    "    # Map each string to its corresponding group\n",
    "    string_groups_filename = \"../data/CurName_fuzzy_groups/CurName_string_groups_{}_threshold.json\".format(threshold)\n",
    "    string_groups_file = Path(string_groups_filename)\n",
    "    if string_groups_file.is_file():\n",
    "        print(\"String groups file already exists: {}\".format(string_groups_file))\n",
    "        with open(string_groups_file) as json_file:\n",
    "            string_groups = json.load(json_file)\n",
    "    else:\n",
    "        print(\"Assigning each of {} strings to one of the {} groups.\".format(len(strings),len(groups)))\n",
    "        string_groups = {}\n",
    "        items = list(groups.items())\n",
    "        for i in range(0,len(items)):\n",
    "            group,values = items[i]\n",
    "            i+=1\n",
    "\n",
    "            msg = \"{}/{}: {}\".format(i,len(groups.items()),group)\n",
    "            sys.stdout.write(\"\\r\" + str(msg).ljust(200, \" \"))\n",
    "            #print(\"{}/{}: {}\".format(i,len(groups.items()),group))\n",
    "            \n",
    "            for value in values:\n",
    "                string_groups[value] = group\n",
    "    \n",
    "        # export string_groups as JSON file\n",
    "        if write_groups: \n",
    "            print(\"Writing string groups to file: {}\".format(string_groups_file))\n",
    "            with open(string_groups_filename, 'w') as json_file:\n",
    "                json.dump(string_groups, json_file)\n",
    "\n",
    "    return string_groups, groups\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fbd949-cdcc-48d5-a63e-6ec2b04cdeae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run the string fuzzy grouping function on the pre-processed (lowercase) CurName column:\n",
    "threshold=90\n",
    "curated_names = df['pCurName']\n",
    "string_groups, groups = group_strings(curated_names, threshold=threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e553eaaa-ba23-4ebb-ae54-fdb8451848bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column, gCurName, in the DataFrame with the grouped strings\n",
    "df['gCurName'] = df['pCurName'].map(string_groups)\n",
    "\n",
    "df.sort_values(by=\"pCurName\",inplace=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17aa47a1-6e86-4b8d-b77f-fa5e2f566697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new CSV file with the pCurName (pre-processed curated names) and gCurName (grouped curated names) columns\n",
    "out_file = \"../data/CurName_fuzzy_groups/grouped_SPARCLE_IDS_curated_{}.csv\".format(threshold)\n",
    "df.to_csv(out_file,index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5478737-be78-40eb-b647-a1381debf6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac78f00e-92c5-44db-a34a-1ddc7249f6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0c0781-5e4e-4834-9f0a-31f8b391759c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c2cad88-2430-421f-9d1b-f27b9e6c7106",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e3462bd-a538-458f-bff4-69de96ef1250",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
